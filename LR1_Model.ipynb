{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3",
   "metadata": {},
   "source": [
    "***Code and documentation written by group members***\n",
    "\n",
    "Model name : LR1\n",
    "\n",
    "Type of Classification: Binary classification - Stress and Non Stress\n",
    "\n",
    "**1. Loading the EEG data samples and its labels**\n",
    "\n",
    "-   The dataset folder consists of an Excel file called \"scales.xls\"\n",
    "    which consists of the subjects' stress level rating from 1-10. We\n",
    "    consider this as the labels for the corresponding EEG samples from\n",
    "    the dataset.\n",
    "\n",
    "-   For example, if we load an EEG sample of subject 10 from the\n",
    "    dataset, his/her stress rating for that mental task is used as the\n",
    "    EEG sample's label.\n",
    "\n",
    "-   The EEG samples file names are formatted in the following manner:\n",
    "    MentalTaskType_sub_no_trial_no.mat - for example:\n",
    "    Relax_sub_2\\_trial2.mat\n",
    "\n",
    "    -   Mental Task Type : either Arithmetic, Stroop, Mirror_Image or\n",
    "        Relax\n",
    "    -   sub_no : Subject Number\n",
    "    -   trial_no : Trial Number\n",
    "\n",
    "    The functions in the following code block and their functionalities:\n",
    "\n",
    "    -   extract_number(file_name_snippet) : extracts the trial number\n",
    "        from the given filename snippet\n",
    "    -   extract_label_address(file_name) : divides the file name into 4\n",
    "        sections and extracts the task type, subject number and trial\n",
    "        number. The function uses this information to calculate and\n",
    "        return the label address on the Excel sheet. The Relax EEG\n",
    "        samples do not have ratings on the Excel sheet, they\n",
    "        automatically return stress rating 0.\n",
    "    -   diff_label(original_stress_label) : the label from the Excel\n",
    "        sheet ranges from 1 to 10. However, we want to group the labels\n",
    "        to either 0 or 1, as we are performing binary classification. So\n",
    "        the EEG samples with label from 1 to 10 were mapped to the\n",
    "        stress label 1 (to signify stress) and the EEG samples which\n",
    "        were from files labelled as \"Relax\" with stress rating 0 were\n",
    "        mapped to stress label 0 (to signify non-stress)\n",
    "    -   read_data(file_array) : takes in a string array of filepaths of\n",
    "        all the EEG sample files and extracts the EEG coordinates from\n",
    "        each filepath. Stores each file's EEG coordinates in an array\n",
    "        and gets its corresponding label using extract_label_address().\n",
    "        This function returns two arrays: an array storing arrays of\n",
    "        each files' EEG coordinates called all_samples and an array\n",
    "        called all_labels, which stores each file's corresponding label\n",
    "        to feed into the model.\n",
    "\n",
    "In \\[1\\]:\n",
    "\n",
    "    import numpy as np  # for numerical operations\n",
    "    from sklearn.model_selection import train_test_split # split data in training and testing\n",
    "    from sklearn.preprocessing import StandardScaler  # standardizing feature values\n",
    "    from glob import glob  # file path expansion\n",
    "    import matplotlib.pyplot as plt   # plotting\n",
    "    import scipy.io    # reading MATLAB files\n",
    "    import os     # OS related functionalities\n",
    "    import pandas as pd   # handle excel data in tabular form\n",
    "    from sklearn.linear_model import LogisticRegression #Import the Logistic Regression model from scikit-learn\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    import seaborn as sns\n",
    "\n",
    "    # for labels in later stages\n",
    "    def extract_number(string):\n",
    "        for char in string:\n",
    "            if char.isdigit():\n",
    "                return int(char)\n",
    "        return None\n",
    "\n",
    "    # takes filepath as parameter, returns indices for address of stress level label in xls file\n",
    "    def extract_label_address(string):\n",
    "        arr=string.split(os.path.sep)[-1].split(\"_\") # ['Arithmetic', 'sub', '10', 'trial1.mat']\n",
    "        base_num=0\n",
    "        if (\"Arithmetic\" in arr[0]):\n",
    "            base_num=1\n",
    "        elif (\"Mirror\" in arr[0]):\n",
    "            base_num=2\n",
    "        elif (\"Stroop\" in arr[0]):\n",
    "            base_num=3\n",
    "        else:\n",
    "            return 0,0\n",
    "        trial_no=extract_number(arr[-1])\n",
    "        if trial_no==2:\n",
    "            base_num+=3\n",
    "        elif trial_no==3:\n",
    "            base_num+=6\n",
    "        return int(arr[-2]),base_num # returns address of cell in excel file\n",
    "\n",
    "    # stress levels are from 1 - 10 in scales.xls, mapped to levels to 0 or 1\n",
    "    def diff_label(stress_label):\n",
    "        if stress_label==0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        return stress_label\n",
    "\n",
    "    # total 480 files, 3 trials for each of the 40 participants in each of the 4 experiments\n",
    "    all_file_paths=sorted(glob(\"filtered_data/*.mat\"))\n",
    "\n",
    "    # reading excel file's stress level labels - array stores the full excel file's contents\n",
    "    stress_levels_arr = pd.read_excel('Dataset_Information/scales.xls').to_numpy()\n",
    "\n",
    "    # reads the data and returns the samples array and its label array\n",
    "    def read_data(file_paths):\n",
    "        data = scipy.io.loadmat(file_paths[0])\n",
    "        eeg_data = data[\"Clean_data\"]\n",
    "        all_samples=[eeg_data]\n",
    "        addr1,addr2=extract_label_address(file_paths[0])\n",
    "        all_labels=[diff_label(stress_levels_arr[addr1][addr2])]\n",
    "        for i in range(1,len(file_paths)):\n",
    "            data = scipy.io.loadmat(file_paths[i])\n",
    "            eeg_data = data[\"Clean_data\"]\n",
    "            all_samples=np.append(all_samples,[eeg_data],axis=0)\n",
    "            addr1,addr2=extract_label_address(file_paths[i])\n",
    "            if (addr1!=0 and addr2!=0): # if addr1, addr2 == 0,0: we are labelling a Relaxation epoch\n",
    "                all_labels=np.append(all_labels,[diff_label(stress_levels_arr[addr1][addr2])],axis=0)\n",
    "            else:\n",
    "                all_labels=np.append(all_labels,[diff_label(0)],axis=0)\n",
    "        return all_samples,all_labels\n",
    "\n",
    "    all_samples,all_labels=read_data(all_file_paths) # shape should be (480,32,3200) and (480,) respectively\n",
    "\n",
    "Structure of all_samples array: Its shape is (480,32,3200) signifying\n",
    "480 files, each containing 32 channels worth of 3200 time samples\n",
    "\n",
    "**2. Preprocessing Data for LR Model**\n",
    "\n",
    "-   Although the EEG data samples are already preprocessed in the sense\n",
    "    of artifact and noise removal, there are additional preprocessing\n",
    "    steps which include:\n",
    "    -   oversampling to balance the classes (1/5th of the dataset was\n",
    "        non-stressed EEG samples, so random oversampling was done to\n",
    "        compensate for the class imbalance)\n",
    "    -   splitting the data into training and testing sets (80% of the\n",
    "        dataset was used for training, 20% was used for testing)\n",
    "    -   flattening the data along the channel axis to prepare it for\n",
    "        input into the LR model.\n",
    "\n",
    "**3. Training the Model**\n",
    "\n",
    "The model trains by fitting itselt to the training preprocessed data\n",
    "using the fit method from sklearn.linear_model. After training, the\n",
    "model makes predictions on the test set using the predict method from\n",
    "sklearn.linear_model.\n",
    "\n",
    "In \\[7\\]:\n",
    "\n",
    "    # identify all indices of non-stress class\n",
    "    non_stress_indices = np.where(all_labels == 0)[0]\n",
    "\n",
    "    # oversampling factor\n",
    "    oversampling_factor = 4\n",
    "\n",
    "    # replicate non-stress samples\n",
    "    replicated_samples = np.repeat(all_samples[non_stress_indices], oversampling_factor, axis=0)\n",
    "    replicated_labels = np.repeat(all_labels[non_stress_indices], oversampling_factor)\n",
    "\n",
    "    # combine with original data\n",
    "    oversampled_samples = np.vstack([all_samples, replicated_samples])\n",
    "    oversampled_labels = np.concatenate([all_labels, replicated_labels])\n",
    "\n",
    "    # split oversampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(oversampled_samples, oversampled_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # flatten data along channel axis\n",
    "    X_train_flatten = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_flatten = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    # create logistic regression model\n",
    "    logistic_model = LogisticRegression(random_state=42)\n",
    "\n",
    "    # train model on training set\n",
    "    logistic_model.fit(X_train_flatten, y_train)\n",
    "\n",
    "    # make predictions on test set\n",
    "    predictions = logistic_model.predict(X_test_flatten)\n",
    "\n",
    "**4. Testing the Model - confusion matrix and classification report**\n",
    "\n",
    "The model is tested in the code section below. Report generated in the\n",
    "output provides a summary of various classification metrics such as\n",
    "precision, recall, F1-score, and support for each class. This reports\n",
    "the evaluation of testing using 20% of the data from the dataset.\n",
    "\n",
    "In \\[8\\]:\n",
    "\n",
    "    # evaluate model's performance\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracy = accuracy *100\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    classification_rep = classification_report(y_test, predictions)\n",
    "\n",
    "    # display the evaluation metrics\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "    print(\"Training Set - Class Distribution:\", np.bincount(y_train))\n",
    "    print(\"Testing Set - Class Distribution:\", np.bincount(y_test))\n",
    "\n",
    "    Test Accuracy: 98.4375\n",
    "    Confusion Matrix:\n",
    "     [[133   0]\n",
    "     [  3  56]]\n",
    "    Classification Report:\n",
    "                   precision    recall  f1-score   support\n",
    "\n",
    "               0       0.98      1.00      0.99       133\n",
    "               1       1.00      0.95      0.97        59\n",
    "\n",
    "        accuracy                           0.98       192\n",
    "       macro avg       0.99      0.97      0.98       192\n",
    "    weighted avg       0.98      0.98      0.98       192\n",
    "\n",
    "    Training Set - Class Distribution: [467 301]\n",
    "    Testing Set - Class Distribution: [133  59]\n",
    "\n",
    "In \\[5\\]:\n",
    "\n",
    "    # simple testing for model - checking if it predicts correctly for a random EEG data sample from dataset\n",
    "\n",
    "    import numpy as np\n",
    "    from scipy.io import loadmat\n",
    "\n",
    "    # load EEG data from .mat file - example\n",
    "\n",
    "    test_index=301\n",
    "\n",
    "    new_user_input = loadmat(all_file_paths[test_index])   # loads eeg data at index 301 for prediction\n",
    "    eeg_data = new_user_input[\"Clean_data\"]\n",
    "\n",
    "    # assuming eeg_data has the shape (32, 3200)\n",
    "\n",
    "    # flatten input data along channel axis\n",
    "    selected_data = eeg_data\n",
    "    input_for_model = selected_data.reshape(1, -1)\n",
    "    input_for_model.shape\n",
    "\n",
    "    # make predictions\n",
    "    prediction = logistic_model.predict(input_for_model)\n",
    "\n",
    "    print(\"Actual Label:\", all_labels[test_index])   # checks the actual label at index 301\n",
    "    print(f'Predicted Label: {prediction[0]}')\n",
    "\n",
    "    Actual Label: 0\n",
    "    Predicted Label: 0\n",
    "\n",
    "**5. Saving the Trained Model**\n",
    "\n",
    "This action ensures that the trained model can be easily retrieved and\n",
    "reused for future predictions or analysis without the need to retrain\n",
    "it. The .h5 version will be used when the model is required to classify\n",
    "a user's EEG sample for the website.\n",
    "\n",
    "In \\[5\\]:\n",
    "\n",
    "    import joblib\n",
    "    import h5py\n",
    "\n",
    "    # save trained Logistic Regression model using joblib\n",
    "    joblib.dump(logistic_model, 'C:/Users/Manoharan/Desktop/LR1.h5')\n",
    "\n",
    "Out\\[5\\]:\n",
    "\n",
    "    ['C:/Users/Manoharan/Desktop/LR1.h5']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
